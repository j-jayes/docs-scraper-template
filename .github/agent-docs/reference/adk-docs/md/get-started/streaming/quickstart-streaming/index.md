Skip to content 

[ ](../../.. "Agent Development Kit")

[ Agent Development Kit ](../../.. "Agent Development Kit")

Python 

Initializing search 




[ adk-python  ](https://github.com/google/adk-python "adk-python") [ adk-js  ](https://github.com/google/adk-js "adk-js") [ adk-go  ](https://github.com/google/adk-go "adk-go") [ adk-java  ](https://github.com/google/adk-java "adk-java")

[ adk-python  ](https://github.com/google/adk-python "adk-python") [ adk-js  ](https://github.com/google/adk-js "adk-js") [ adk-go  ](https://github.com/google/adk-go "adk-go") [ adk-java  ](https://github.com/google/adk-java "adk-java")

  * [ Home  ](../../..)

Home 
  * Build Agents  Build Agents 
    * [ Get Started  ](../../)

Get Started 
      * [ Python  ](../../python/)
      * [ TypeScript  ](../../typescript/)
      * [ Go  ](../../go/)
      * [ Java  ](../../java/)
    * [ Build your Agent  ](../../../tutorials/)

Build your Agent 
      * [ Multi-tool agent  ](../../quickstart/)
      * [ Agent team  ](../../../tutorials/agent-team/)
      * [ Streaming agent  ](../)

Streaming agent 
        * Python  [ Python  ](./) Table of contents 
          * Supported models for voice/video streaming 
          * 1\. Setup Environment & Install ADK 
          * 2\. Project Structure 
            * agent.py 
          * 3\. Set up the platform 
          * 4\. Try the agent with adk web 
            * Try with text 
            * Try with voice and video 
            * Stop the tool 
            * Note on ADK Streaming 
          * Next steps: build custom streaming app 
        * [ Java  ](../quickstart-streaming-java/)
      * [ Visual Builder  ](../../../visual-builder/)
      * [ Coding with AI  ](../../../tutorials/coding-with-ai/)
      * [ Advanced setup  ](../../installation/)
    * [ Agents  ](../../../agents/)

Agents 
      * [ LLM agents  ](../../../agents/llm-agents/)
      * [ Workflow agents  ](../../../agents/workflow-agents/)

Workflow agents 
        * [ Sequential agents  ](../../../agents/workflow-agents/sequential-agents/)
        * [ Loop agents  ](../../../agents/workflow-agents/loop-agents/)
        * [ Parallel agents  ](../../../agents/workflow-agents/parallel-agents/)
      * [ Custom agents  ](../../../agents/custom-agents/)
      * [ Multi-agent systems  ](../../../agents/multi-agents/)
      * [ Agent Config  ](../../../agents/config/)
      * [ Models & Authentication  ](../../../agents/models/)
    * [ Tools for Agents  ](../../../tools/)

Tools for Agents 
      * [ Gemini API tools  ](../../../tools/gemini-api/)

Gemini API tools 
        * [ Code Execution  ](../../../tools/gemini-api/code-execution/)
        * [ Computer use  ](../../../tools/gemini-api/computer-use/)
        * [ Google Search  ](../../../tools/gemini-api/google-search/)
      * [ Google Cloud tools  ](../../../tools/google-cloud/)

Google Cloud tools 
        * [ Apigee API Hub  ](../../../tools/google-cloud/apigee-api-hub/)
        * [ Application Integration  ](../../../tools/google-cloud/application-integration/)
        * [ BigQuery  ](../../../tools/google-cloud/bigquery/)
        * [ Bigtable  ](../../../tools/google-cloud/bigtable/)
        * [ Cloud API Registry  ](../../../tools/google-cloud/api-registry/)
        * [ Code Execution with Agent Engine  ](../../../tools/google-cloud/code-exec-agent-engine/)
        * [ GKE Code Executor  ](../../../tools/google-cloud/gke-code-executor/)
        * [ MCP Toolbox for Databases  ](../../../tools/google-cloud/mcp-toolbox-for-databases/)
        * [ RAG Engine  ](../../../tools/google-cloud/vertex-ai-rag-engine/)
        * [ Spanner  ](../../../tools/google-cloud/spanner/)
        * [ Vertex AI Search  ](../../../tools/google-cloud/vertex-ai-search/)
      * [ Third-party tools  ](../../../tools/third-party/)

Third-party tools 
        * [ Atlassian  ](../../../tools/third-party/atlassian/)
        * [ GitHub  ](../../../tools/third-party/github/)
        * [ GitLab  ](../../../tools/third-party/gitlab/)
        * [ Hugging Face  ](../../../tools/third-party/hugging-face/)
        * [ Linear  ](../../../tools/third-party/linear/)
        * [ n8n  ](../../../tools/third-party/n8n/)
        * [ Notion  ](../../../tools/third-party/notion/)
        * [ PayPal  ](../../../tools/third-party/paypal/)
        * [ Qdrant  ](../../../tools/third-party/qdrant/)
        * [ Agentic UI (AG-UI)  ](../../../tools/third-party/ag-ui/)
      * [ Tool limitations  ](../../../tools/limitations/)
    * [ Custom Tools  ](../../../tools-custom/)

Custom Tools 
      * Function tools  Function tools 
        * [ Overview  ](../../../tools-custom/function-tools/)
        * [ Tool performance  ](../../../tools-custom/performance/)
        * [ Action confirmations  ](../../../tools-custom/confirmation/)
      * [ MCP tools  ](../../../tools-custom/mcp-tools/)
      * [ OpenAPI tools  ](../../../tools-custom/openapi-tools/)
      * [ Authentication  ](../../../tools-custom/authentication/)
  * Run Agents  Run Agents 
    * [ Agent Runtime  ](../../../runtime/)

Agent Runtime 
      * [ Runtime Config  ](../../../runtime/runconfig/)
      * [ API Server  ](../../../runtime/api-server/)
      * [ Resume Agents  ](../../../runtime/resume/)
    * [ Deployment  ](../../../deploy/)

Deployment 
      * [ Agent Engine  ](../../../deploy/agent-engine/)

Agent Engine 
        * [ Standard deployment  ](../../../deploy/agent-engine/deploy/)
        * [ Agent Starter Pack  ](../../../deploy/agent-engine/asp/)
        * [ Test deployed agents  ](../../../deploy/agent-engine/test/)
      * [ Cloud Run  ](../../../deploy/cloud-run/)
      * [ GKE  ](../../../deploy/gke/)
    * Observability  Observability 
      * [ Logging  ](../../../observability/logging/)
      * [ Cloud Trace  ](../../../observability/cloud-trace/)
      * [ BigQuery Agent Analytics  ](../../../observability/bigquery-agent-analytics/)
      * [ AgentOps  ](../../../observability/agentops/)
      * [ Arize AX  ](../../../observability/arize-ax/)
      * [ Freeplay  ](../../../observability/freeplay/)
      * [ MLflow  ](../../../observability/mlflow/)
      * [ Monocle  ](../../../observability/monocle/)
      * [ Phoenix  ](../../../observability/phoenix/)
      * [ W&B; Weave  ](../../../observability/weave/)
    * [ Evaluation  ](../../../evaluate/)

Evaluation 
      * [ Criteria  ](../../../evaluate/criteria/)
      * [ User Simulation  ](../../../evaluate/user-sim/)
    * [ Safety and Security  ](../../../safety/)

Safety and Security 
  * Components  Components 
    * [ Technical Overview  ](../../about/)
    * [ Context  ](../../../context/)

Context 
      * [ Context caching  ](../../../context/caching/)
      * [ Context compression  ](../../../context/compaction/)
    * [ Sessions & Memory  ](../../../sessions/)

Sessions & Memory 
      * Sessions  Sessions 
        * [ Overview  ](../../../sessions/session/)
        * [ Rewind sessions  ](../../../sessions/rewind/)
      * [ State  ](../../../sessions/state/)
      * [ Memory  ](../../../sessions/memory/)
      * [ Vertex AI Express Mode  ](../../../sessions/express-mode/)
    * [ Callbacks  ](../../../callbacks/)

Callbacks 
      * [ Types of callbacks  ](../../../callbacks/types-of-callbacks/)
      * [ Callback patterns  ](../../../callbacks/design-patterns-and-best-practices/)
    * [ Artifacts  ](../../../artifacts/)

Artifacts 
    * [ Events  ](../../../events/)

Events 
    * [ Apps  ](../../../apps/)

Apps 
    * [ Plugins  ](../../../plugins/)

Plugins 
      * [ Reflect and retry  ](../../../plugins/reflect-and-retry/)
    * [ MCP  ](../../../mcp/)

MCP 
    * [ A2A Protocol  ](../../../a2a/)

A2A Protocol 
      * [ Introduction to A2A  ](../../../a2a/intro/)
      * A2A Quickstart (Exposing)  A2A Quickstart (Exposing) 
        * [ Python  ](../../../a2a/quickstart-exposing/)
        * [ Go  ](../../../a2a/quickstart-exposing-go/)
      * A2A Quickstart (Consuming)  A2A Quickstart (Consuming) 
        * [ Python  ](../../../a2a/quickstart-consuming/)
        * [ Go  ](../../../a2a/quickstart-consuming-go/)
    * [ Bidi-streaming (live)  ](../../../streaming/)

Bidi-streaming (live) 
      * Bidi-streaming development guide series  Bidi-streaming development guide series 
        * [ Part 1. Intro to streaming  ](../../../streaming/dev-guide/part1/)
        * [ Part 2. Sending messages  ](../../../streaming/dev-guide/part2/)
        * [ Part 3. Event handling  ](../../../streaming/dev-guide/part3/)
        * [ Part 4. Run configuration  ](../../../streaming/dev-guide/part4/)
        * [ Part 5. Audio, Images, and Video  ](../../../streaming/dev-guide/part5/)
      * [ Streaming Tools  ](../../../streaming/streaming-tools/)
      * [ Configuring Bidi-streaming behavior  ](../../../streaming/configuration/)
    * Grounding  Grounding 
      * [ Understanding Google Search Grounding  ](../../../grounding/google_search_grounding/)
      * [ Understanding Vertex AI Search Grounding  ](../../../grounding/vertex_ai_search_grounding/)
  * Reference  Reference 
    * [ Release Notes  ](../../../release-notes/)
    * [ API Reference  ](../../../api-reference/)

API Reference 
      * [ Python ADK  ](../../../api-reference/python/)
      * [ Typescript ADK  ](../../../api-reference/typescript/)
      * [ Go ADK  ](https://pkg.go.dev/google.golang.org/adk)
      * [ Java ADK  ](../../../api-reference/java/)
      * [ CLI Reference  ](../../../api-reference/cli/)
      * [ Agent Config Reference  ](../../../api-reference/agentconfig/)
      * [ REST API  ](../../../api-reference/rest/)
    * [ Community Resources  ](../../../community/)
    * [ Contributing Guide  ](../../../contributing-guide/)



Table of contents 

  * Supported models for voice/video streaming 
  * 1\. Setup Environment & Install ADK 
  * 2\. Project Structure 
    * agent.py 
  * 3\. Set up the platform 
  * 4\. Try the agent with adk web 
    * Try with text 
    * Try with voice and video 
    * Stop the tool 
    * Note on ADK Streaming 
  * Next steps: build custom streaming app 



  1. [ Build Agents  ](../../)
  2. [ Build your Agent  ](../../../tutorials/)
  3. [ Streaming agent  ](../)

[ ](https://github.com/google/adk-docs/edit/main/docs/get-started/streaming/quickstart-streaming.md "Edit this page") [ ](https://github.com/google/adk-docs/raw/main/docs/get-started/streaming/quickstart-streaming.md "View source of this page")

# Build a streaming agent with Python¶

With this quickstart, you'll learn to create a simple agent and use ADK Streaming to enable voice and video communication with it that is low-latency and bidirectional. We will install ADK, set up a basic "Google Search" agent, try running the agent with Streaming with `adk web` tool, and then explain how to build a simple asynchronous web app by yourself using ADK Streaming and [FastAPI](https://fastapi.tiangolo.com/).

**Note:** This guide assumes you have experience using a terminal in Windows, Mac, and Linux environments.

## Supported models for voice/video streaming¶

In order to use voice/video streaming in ADK, you will need to use Gemini models that support the Live API. You can find the **model ID(s)** that supports the Gemini Live API in the documentation:

  * [Google AI Studio: Gemini Live API](https://ai.google.dev/gemini-api/docs/models#live-api)
  * [Vertex AI: Gemini Live API](https://cloud.google.com/vertex-ai/generative-ai/docs/live-api)



## 1\. Setup Environment & Install ADK¶

Create & Activate Virtual Environment (Recommended):
    
    
    # Create
    python -m venv .venv
    # Activate (each new terminal)
    # macOS/Linux: source .venv/bin/activate
    # Windows CMD: .venv\Scripts\activate.bat
    # Windows PowerShell: .venv\Scripts\Activate.ps1
    

Install ADK:
    
    
    pip install google-adk
    

## 2\. Project Structure¶

Create the following folder structure with empty files:
    
    
    adk-streaming/  # Project folder
    └── app/ # the web app folder
        ├── .env # Gemini API key
        └── google_search_agent/ # Agent folder
            ├── __init__.py # Python package
            └── agent.py # Agent definition
    

### agent.py¶

Copy-paste the following code block into the `agent.py` file.

For `model`, please double check the model ID as described earlier in the Models section.
    
    
    from google.adk.agents import Agent
    from google.adk.tools import google_search  # Import the tool
    
    root_agent = Agent(
       # A unique name for the agent.
       name="basic_search_agent",
       # The Large Language Model (LLM) that agent will use.
       # Please fill in the latest model id that supports live from
       # https://google.github.io/adk-docs/get-started/streaming/quickstart-streaming/#supported-models
       model="...",  # for example: model="gemini-2.0-flash-live-001" or model="gemini-2.0-flash-live-preview-04-09"
       # A short description of the agent's purpose.
       description="Agent to answer questions using Google Search.",
       # Instructions to set the agent's behavior.
       instruction="You are an expert researcher. You always stick to the facts.",
       # Add google_search tool to perform grounding with Google search.
       tools=[google_search]
    )
    

`agent.py` is where all your agent(s)' logic will be stored, and you must have a `root_agent` defined.

Notice how easily you integrated [grounding with Google Search](https://ai.google.dev/gemini-api/docs/grounding?lang=python#configure-search) capabilities. The `Agent` class and the `google_search` tool handle the complex interactions with the LLM and grounding with the search API, allowing you to focus on the agent's _purpose_ and _behavior_.

Copy-paste the following code block to `__init__.py` file.

__init__.py
    
    
    from . import agent
    

## 3\. Set up the platform¶

To run the agent, choose a platform from either Google AI Studio or Google Cloud Vertex AI:

Gemini - Google AI StudioGemini - Google Cloud Vertex AI

  1. Get an API key from [Google AI Studio](https://aistudio.google.com/apikey).
  2. Open the **`.env`** file located inside (`app/`) and copy-paste the following code.

.env
         
         GOOGLE_GENAI_USE_VERTEXAI=FALSE
         GOOGLE_API_KEY=PASTE_YOUR_ACTUAL_API_KEY_HERE
         

  3. Replace `PASTE_YOUR_ACTUAL_API_KEY_HERE` with your actual `API KEY`.




  1. You need an existing [Google Cloud](https://cloud.google.com/?e=48754805&hl=en) account and a project.
     * Set up a [Google Cloud project](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal#setup-gcp)
     * Set up the [gcloud CLI](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal#setup-local)
     * Authenticate to Google Cloud, from the terminal by running `gcloud auth login`.
     * [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).
  2. Open the **`.env`** file located inside (`app/`). Copy-paste the following code and update the project ID and location.

.env
         
         GOOGLE_GENAI_USE_VERTEXAI=TRUE
         GOOGLE_CLOUD_PROJECT=PASTE_YOUR_ACTUAL_PROJECT_ID
         GOOGLE_CLOUD_LOCATION=us-central1
         




## 4\. Try the agent with `adk web`¶

Now it's ready to try the agent. Run the following command to launch the **dev UI**. First, make sure to set the current directory to `app`:
    
    
    cd app
    

Also, set `SSL_CERT_FILE` variable with the following command. This is required for the voice and video tests later.

OS X & LinuxWindows
    
    
    export SSL_CERT_FILE=$(python -m certifi)
    
    
    
    $env:SSL_CERT_FILE = (python -m certifi)
    

Then, run the dev UI:
    
    
    adk web
    

Note for Windows users

When hitting the `_make_subprocess_transport NotImplementedError`, consider using `adk web --no-reload` instead.

Caution: ADK Web for development only

ADK Web is **_not meant for use in production deployments_**. You should use ADK Web for development and debugging purposes only.

Open the URL provided (usually `http://localhost:8000` or `http://127.0.0.1:8000`) **directly in your browser**. This connection stays entirely on your local machine. Select `google_search_agent`.

### Try with text¶

Try the following prompts by typing them in the UI.

  * What is the weather in New York?
  * What is the time in New York?
  * What is the weather in Paris?
  * What is the time in Paris?



The agent will use the google_search tool to get the latest information to answer those questions.

### Try with voice and video¶

To try with voice, reload the web browser, click the microphone button to enable the voice input, and ask the same question in voice. You will hear the answer in voice in real-time.

To try with video, reload the web browser, click the camera button to enable the video input, and ask questions like "What do you see?". The agent will answer what they see in the video input.

(Just clicking the microphone or camera button once is enough. Your voice or video will be streamed to models and the model response will be streamed back continuously. Clicking on the microphone or camera button multiple times is not supported.)

### Stop the tool¶

Stop `adk web` by pressing `Ctrl-C` on the console.

### Note on ADK Streaming¶

The following features will be supported in the future versions of the ADK Streaming: Callback, LongRunningTool, ExampleTool, and Shell agent (e.g. SequentialAgent).

Congratulations! You've successfully created and interacted with your first Streaming agent using ADK!

## Next steps: build custom streaming app¶

The [Bidi-streaming development guide series](../../../streaming/dev-guide/part1/) gives an overview of the server and client code for a custom asynchronous web app built with ADK Streaming, enabling real-time, bidirectional audio and text communication.

Back to top  [ Previous  Build a streaming agent  ](../) [ Next  Java  ](../quickstart-streaming-java/)

Copyright Google 2025  |  [Terms](//policies.google.com/terms)  |  [Privacy](//policies.google.com/privacy)  |  Manage cookies

Made with [ Material for MkDocs ](https://squidfunk.github.io/mkdocs-material/)

#### Cookie consent

We use cookies to recognize repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find the information they need. With your consent, you're helping us to make our documentation better.

  * Google Analytics 
  * GitHub 



Accept Manage settings
